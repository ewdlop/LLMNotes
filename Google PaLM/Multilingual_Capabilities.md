# Multilingual capabilities of PaLM 2

## Research Findings

PaLM 2 has been heavily trained on multilingual text, spanning more than 100 languages. This allows it to perform significantly better than its predecessors on multilingual tasks.

### Key Observations

1.  **Idiom Understanding**: The model shows an improved ability to understand and generate idioms across different languages, which is a common stumbling block for literal translation models.
2.  **Nuance**: It captures cultural nuances and subtle meaning shifts in translation and generation.
3.  **Language Coverage**: High proficiency in widely spoken languages as well as improvements in low-resource languages compared to earlier iterations.

### Potential Applications

*   **Real-time Translation**: With its efficiency (especially the Gecko variant), it could power on-device translation.
*   **Cross-lingual Information Retrieval**: Searching for concepts in one language and retrieving relevant results from documents in other languages.
*   **Multilingual Chatbots**: Creating agents that can seamlessly switch between languages in a single conversation.
